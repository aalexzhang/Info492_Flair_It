{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jsonl Cleaning and Jsonl -> Dataframe -> CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code I created a method which utalizes the jsonl file cade pulled from pushshift and basically goes through all the different values and pulls out the necessary values we'll be using within our model and some other necessary information for data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_jsonl_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                entry = json.loads(line.strip())\n",
    "                title = entry.get('title')\n",
    "                selftext = entry.get('selftext')\n",
    "                link_flair_text = entry.get('link_flair_text')\n",
    "                post_id = entry.get('id')\n",
    "                url = entry.get('url')\n",
    "                num_comments = entry.get('num_comments')\n",
    "                score = entry.get('score')\n",
    "\n",
    "                if link_flair_text == 'None':\n",
    "                    continue\n",
    "                \n",
    "                data.append({\n",
    "                    'title': title,\n",
    "                    'selftext': selftext,\n",
    "                    'link_flair_text': link_flair_text,\n",
    "                    'id': post_id,\n",
    "                    'url': url,\n",
    "                    'num_comments': num_comments,\n",
    "                    'score': score\n",
    "                    \n",
    "                })\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Error decoding JSON line:\", line)\n",
    "    return data\n",
    "\n",
    "file_path = 'r_udub_posts.jsonl'\n",
    "parsed_data = parse_jsonl_file(file_path)\n",
    "\n",
    "df_jsonl = pd.DataFrame(parsed_data)\n",
    "\n",
    "df_jsonl.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Part of the code moves the now created dataframe and transforms it into a CSV so it's easier to handle and allows for us to all work with the same Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_jsonl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr_udub_posts.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdf_jsonl\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(csv_file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame saved as CSV:\u001b[39m\u001b[38;5;124m\"\u001b[39m, csv_file_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_jsonl' is not defined"
     ]
    }
   ],
   "source": [
    "csv_file_path = 'r_udub_posts.csv'\n",
    "df_jsonl.to_csv(csv_file_path, index=False)\n",
    "print(\"DataFrame saved as CSV:\", csv_file_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How accuracy is a multinomial Naive Bayes Model for predicting different flairs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we wanted to try a fairly standard model to kinda get a baseline on one how our data works and get a starting point in which we can iterate and look back on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Any UW redditors want to meet up Thursday 10/2...</td>\n",
       "      <td>We failed on 10/22, but I think with a week of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9y4hg</td>\n",
       "      <td>https://www.reddit.com/r/udub/comments/9y4hg/a...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We need a UW-ified logo.</td>\n",
       "      <td>If someone here has arcane skill in the graphi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9ywtc</td>\n",
       "      <td>https://www.reddit.com/r/udub/comments/9ywtc/w...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thursday bowling success!</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9z66c</td>\n",
       "      <td>https://www.reddit.com/r/udub/comments/9z66c/t...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Next UW meetup: Thursday, 11/5 at 11:00am in t...</td>\n",
       "      <td>This time we will be playing ping pong followe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a0ail</td>\n",
       "      <td>https://www.reddit.com/r/udub/comments/a0ail/n...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Next meetup: December 3rd. Need ideas</td>\n",
       "      <td>Alright, so who is up for a December 3rd meetu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a9lq8</td>\n",
       "      <td>https://www.reddit.com/r/udub/comments/a9lq8/n...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Any UW redditors want to meet up Thursday 10/2...   \n",
       "1                           We need a UW-ified logo.   \n",
       "2                          Thursday bowling success!   \n",
       "3  Next UW meetup: Thursday, 11/5 at 11:00am in t...   \n",
       "4              Next meetup: December 3rd. Need ideas   \n",
       "\n",
       "                                            selftext link_flair_text     id  \\\n",
       "0  We failed on 10/22, but I think with a week of...             NaN  9y4hg   \n",
       "1  If someone here has arcane skill in the graphi...             NaN  9ywtc   \n",
       "2                                          [deleted]             NaN  9z66c   \n",
       "3  This time we will be playing ping pong followe...             NaN  a0ail   \n",
       "4  Alright, so who is up for a December 3rd meetu...             NaN  a9lq8   \n",
       "\n",
       "                                                 url  num_comments  score  \n",
       "0  https://www.reddit.com/r/udub/comments/9y4hg/a...             6      4  \n",
       "1  https://www.reddit.com/r/udub/comments/9ywtc/w...             2      3  \n",
       "2  https://www.reddit.com/r/udub/comments/9z66c/t...             2      3  \n",
       "3  https://www.reddit.com/r/udub/comments/a0ail/n...             2      4  \n",
       "4  https://www.reddit.com/r/udub/comments/a9lq8/n...             7      2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = pd.read_csv('r_udub_posts.csv')\n",
    "posts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'PSA', 'Rant', 'Random', 'Meme', 'Question', 'Discussion',\n",
       "       'Academics', 'Student Life', 'Help', 'Event', 'Video',\n",
       "       'Admissions', 'Advice', 'Poll', 'poll', 'No unrelated posts'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts['link_flair_text'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next code is pretty much our main filter to bring our data from raw data into data which we can be fed into a model. In this case we combined the title and body text into one column so we can have more text tokenizer and utalize.Alongside this we also got rid of any posts which had not body, no flair or if the post is removed/deleted. Finally we removed any flairs not currently in use then lowercased them all to combine redundant flairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combined_text</th>\n",
       "      <th>link_flair_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28066</th>\n",
       "      <td>thoughts on madrona? i have an emotional suppo...</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28077</th>\n",
       "      <td>soc 222 anyone has took or taking soc222(socio...</td>\n",
       "      <td>academics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28080</th>\n",
       "      <td>betsy evans - ling/anth 233 does anyone have a...</td>\n",
       "      <td>academics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28083</th>\n",
       "      <td>tell me what you want from remote teaching? th...</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28088</th>\n",
       "      <td>efs experience/thoughts/opinions! i just regis...</td>\n",
       "      <td>discussion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           combined_text link_flair_text\n",
       "28066  thoughts on madrona? i have an emotional suppo...      discussion\n",
       "28077  soc 222 anyone has took or taking soc222(socio...       academics\n",
       "28080  betsy evans - ling/anth 233 does anyone have a...       academics\n",
       "28083  tell me what you want from remote teaching? th...      discussion\n",
       "28088  efs experience/thoughts/opinions! i just regis...      discussion"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts['combined_text'] = posts['title'] + \" \" + posts['selftext'].fillna(\"\")\n",
    "flair_categories = [\"admissions\", \"academics\", \"student life\", \"advice\", \"discussion\", \"meme\", \"rant\", \"psa\", \"event\", \"poll\"]\n",
    "\n",
    "flairedNotSelf = posts[(posts['link_flair_text'].notnull()) & (posts['selftext'] != '[removed]') & (posts['selftext'] != '[deleted]') & posts['selftext'].notnull()]\n",
    "ModelDataLower = flairedNotSelf.apply(lambda col: col.str.lower() if col.dtype == 'object' else col)\n",
    "ModelDataFiltered = ModelDataLower[ModelDataLower['link_flair_text'].isin(flair_categories)][['combined_text', 'link_flair_text']]\n",
    "\n",
    "ModelDataFiltered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9031\n"
     ]
    }
   ],
   "source": [
    "print(len(ModelDataFiltered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found the distribution of flairs so we can understand the data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "link_flair_text\n",
       "advice          2360\n",
       "academics       2100\n",
       "student life    1551\n",
       "admissions       977\n",
       "discussion       865\n",
       "poll             464\n",
       "rant             388\n",
       "psa              138\n",
       "event            128\n",
       "meme              60\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelDataFiltered.groupby('link_flair_text').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below we just did a standard 80/20 split and kept random state 52 to get the same split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7224\n",
      "1807\n",
      "7224\n",
      "1807\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ModelDataFiltered['combined_text'], ModelDataFiltered['link_flair_text'], test_size=0.2, random_state=52)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we vectorized the data using TF-IDF in order to remove common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we trained the model using the sklearn multinomial naive bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4043457723193198\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   academics       0.67      0.52      0.59       470\n",
      "  admissions       0.77      0.04      0.08       226\n",
      "      advice       0.29      0.86      0.43       468\n",
      "  discussion       0.00      0.00      0.00       202\n",
      "       event       0.00      0.00      0.00        40\n",
      "        meme       1.00      0.01      0.02       116\n",
      "        poll       0.85      0.64      0.73        88\n",
      "         psa       0.00      0.00      0.00        58\n",
      "        rant       0.00      0.00      0.00        76\n",
      "student life       0.55      0.38      0.45       373\n",
      "\n",
      "    accuracy                           0.40      2117\n",
      "   macro avg       0.41      0.24      0.23      2117\n",
      "weighted avg       0.48      0.40      0.34      2117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tyler\\anaconda3\\envs\\INFO492\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tyler\\anaconda3\\envs\\INFO492\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tyler\\anaconda3\\envs\\INFO492\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One limitations of this model are primarily due to the useage of a TF-IDF vectorization as because it utalizes a bag of works approach it ignores the context and order of words and thus can limit out models abiltiy to extract relationships between words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A second limitation of this approach is we have a data imbalance as some flairs are more commonly utalized and thus our model may be weigted more towards classifying those flairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going forward we plan on trying to utalize Word2Vec which is able to interpret context more easily and also we plan to discuss if we want to put data mininimum on the amount of flairs necessary "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INFO492",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
