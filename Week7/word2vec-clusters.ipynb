{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6afb5a9b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-03T23:24:21.992254Z",
     "iopub.status.busy": "2024-05-03T23:24:21.991879Z",
     "iopub.status.idle": "2024-05-03T23:24:36.607952Z",
     "shell.execute_reply": "2024-05-03T23:24:36.606857Z"
    },
    "papermill": {
     "duration": 14.625711,
     "end_time": "2024-05-03T23:24:36.610531",
     "exception": false,
     "start_time": "2024-05-03T23:24:21.984820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/kaggle/input/alldatafiltered/AllDataFilteredNoBody.csv\n",
      "/kaggle/input/alldatafiltered/AllDataFiltered.csv\n",
      "/kaggle/input/notcombined/r_udub_posts_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe9ceb99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:24:36.622981Z",
     "iopub.status.busy": "2024-05-03T23:24:36.621611Z",
     "iopub.status.idle": "2024-05-03T23:24:36.631698Z",
     "shell.execute_reply": "2024-05-03T23:24:36.630602Z"
    },
    "papermill": {
     "duration": 0.018667,
     "end_time": "2024-05-03T23:24:36.634182",
     "exception": false,
     "start_time": "2024-05-03T23:24:36.615515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(text, tokenizer, stopwords):\n",
    "    \"\"\"Pre-process text and generate tokens\n",
    "\n",
    "    Args:\n",
    "        text: Text to tokenize.\n",
    "\n",
    "    Returns:\n",
    "        Tokenized text.\n",
    "    \"\"\"\n",
    "    text = str(text).lower()  # Lowercase words\n",
    "    text = re.sub(r\"\\[(.*?)\\]\", \"\", text)  # Remove [+XYZ chars] in content\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Remove multiple spaces in content\n",
    "    text = re.sub(r\"\\w+…|…\", \"\", text)  # Remove ellipsis (and last word)\n",
    "    text = re.sub(r\"(?<=\\w)-(?=\\w)\", \" \", text)  # Replace dash between words\n",
    "    text = re.sub(\n",
    "        f\"[{re.escape(string.punctuation)}]\", \"\", text\n",
    "    )  # Remove punctuation\n",
    "\n",
    "    tokens = tokenizer(text)  # Get tokens from text\n",
    "    tokens = [t for t in tokens if not t in stopwords]  # Remove stopwords\n",
    "    tokens = [\"\" if t.isdigit() else t for t in tokens]  # Remove digits\n",
    "    tokens = [t for t in tokens if len(t) > 1]  # Remove short tokens\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf529c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:24:36.645569Z",
     "iopub.status.busy": "2024-05-03T23:24:36.645164Z",
     "iopub.status.idle": "2024-05-03T23:24:37.578545Z",
     "shell.execute_reply": "2024-05-03T23:24:37.577432Z"
    },
    "papermill": {
     "duration": 0.941858,
     "end_time": "2024-05-03T23:24:37.580897",
     "exception": false,
     "start_time": "2024-05-03T23:24:36.639039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>bodyTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28049</td>\n",
       "      <td>r/udub mods</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Meme</td>\n",
       "      <td>g3g8ab</td>\n",
       "      <td>https://i.redd.it/d4wj47suqht41.png</td>\n",
       "      <td>6</td>\n",
       "      <td>342</td>\n",
       "      <td>r/udub mods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28050</td>\n",
       "      <td>UW Nursing Frustration</td>\n",
       "      <td>If any one here is thinking of applying to the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>g3g9sa</td>\n",
       "      <td>https://www.reddit.com/r/udub/comments/g3g9sa/...</td>\n",
       "      <td>16</td>\n",
       "      <td>61</td>\n",
       "      <td>UW Nursing Frustration If any one here is thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28051</td>\n",
       "      <td>Does anyone know if parking is free on campus ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>g3i0rg</td>\n",
       "      <td>https://www.reddit.com/r/udub/comments/g3i0rg/...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Does anyone know if parking is free on campus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28052</td>\n",
       "      <td>Not the OP, but posting this again</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>g3i63f</td>\n",
       "      <td>https://i.redd.it/hkq6gklzgit41.png</td>\n",
       "      <td>29</td>\n",
       "      <td>163</td>\n",
       "      <td>Not the OP, but posting this again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28053</td>\n",
       "      <td>Help deciding between UW engineering and anoth...</td>\n",
       "      <td>Hey everybody! I was admitted as a DTC enginee...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>g3ievx</td>\n",
       "      <td>https://www.reddit.com/r/udub/comments/g3ievx/...</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>Help deciding between UW engineering and anoth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47054</th>\n",
       "      <td>75103</td>\n",
       "      <td>Anyone going to Seattle International Film Fes...</td>\n",
       "      <td>Anyone planning on attending any screenings th...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>1c8362f</td>\n",
       "      <td>https://www.reddit.com/r/udub/comments/1c8362f...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Anyone going to Seattle International Film Fes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47055</th>\n",
       "      <td>75104</td>\n",
       "      <td>Is taking Physics and ochem at the same time a...</td>\n",
       "      <td>i’m debating to take physics and ochem togethe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1c87cme</td>\n",
       "      <td>https://www.reddit.com/r/udub/comments/1c87cme...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Is taking Physics and ochem at the same time a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47056</th>\n",
       "      <td>75105</td>\n",
       "      <td>Microbio and Weed-out classes</td>\n",
       "      <td>I know this subreddit is probably being floode...</td>\n",
       "      <td>Advice</td>\n",
       "      <td>1c8a9zh</td>\n",
       "      <td>https://www.reddit.com/r/udub/comments/1c8a9zh...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Microbio and Weed-out classes I know this subr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47057</th>\n",
       "      <td>75106</td>\n",
       "      <td>Did I miss the window for a house rental for t...</td>\n",
       "      <td>My friend and I are month-to-month right now a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1c8aw8t</td>\n",
       "      <td>https://www.reddit.com/r/udub/comments/1c8aw8t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Did I miss the window for a house rental for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47058</th>\n",
       "      <td>75107</td>\n",
       "      <td>Varanasi Summer Internship Decision</td>\n",
       "      <td>Does anyone in math/acms applied for the Varan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1c8b0zd</td>\n",
       "      <td>https://www.reddit.com/r/udub/comments/1c8b0zd...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Varanasi Summer Internship Decision Does anyo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47059 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              title  \\\n",
       "0           28049                                        r/udub mods   \n",
       "1           28050                             UW Nursing Frustration   \n",
       "2           28051  Does anyone know if parking is free on campus ...   \n",
       "3           28052                 Not the OP, but posting this again   \n",
       "4           28053  Help deciding between UW engineering and anoth...   \n",
       "...           ...                                                ...   \n",
       "47054       75103  Anyone going to Seattle International Film Fes...   \n",
       "47055       75104  Is taking Physics and ochem at the same time a...   \n",
       "47056       75105                      Microbio and Weed-out classes   \n",
       "47057       75106  Did I miss the window for a house rental for t...   \n",
       "47058       75107                Varanasi Summer Internship Decision   \n",
       "\n",
       "                                                selftext link_flair_text  \\\n",
       "0                                                    NaN            Meme   \n",
       "1      If any one here is thinking of applying to the...             NaN   \n",
       "2                                                    NaN             NaN   \n",
       "3                                                    NaN             NaN   \n",
       "4      Hey everybody! I was admitted as a DTC enginee...             NaN   \n",
       "...                                                  ...             ...   \n",
       "47054  Anyone planning on attending any screenings th...      Discussion   \n",
       "47055  i’m debating to take physics and ochem togethe...             NaN   \n",
       "47056  I know this subreddit is probably being floode...          Advice   \n",
       "47057  My friend and I are month-to-month right now a...             NaN   \n",
       "47058  Does anyone in math/acms applied for the Varan...             NaN   \n",
       "\n",
       "            id                                                url  \\\n",
       "0       g3g8ab                https://i.redd.it/d4wj47suqht41.png   \n",
       "1       g3g9sa  https://www.reddit.com/r/udub/comments/g3g9sa/...   \n",
       "2       g3i0rg  https://www.reddit.com/r/udub/comments/g3i0rg/...   \n",
       "3       g3i63f                https://i.redd.it/hkq6gklzgit41.png   \n",
       "4       g3ievx  https://www.reddit.com/r/udub/comments/g3ievx/...   \n",
       "...        ...                                                ...   \n",
       "47054  1c8362f  https://www.reddit.com/r/udub/comments/1c8362f...   \n",
       "47055  1c87cme  https://www.reddit.com/r/udub/comments/1c87cme...   \n",
       "47056  1c8a9zh  https://www.reddit.com/r/udub/comments/1c8a9zh...   \n",
       "47057  1c8aw8t  https://www.reddit.com/r/udub/comments/1c8aw8t...   \n",
       "47058  1c8b0zd  https://www.reddit.com/r/udub/comments/1c8b0zd...   \n",
       "\n",
       "       num_comments  score                                          bodyTitle  \n",
       "0                 6    342                                       r/udub mods   \n",
       "1                16     61  UW Nursing Frustration If any one here is thin...  \n",
       "2                 2      2  Does anyone know if parking is free on campus ...  \n",
       "3                29    163                Not the OP, but posting this again   \n",
       "4                17      6  Help deciding between UW engineering and anoth...  \n",
       "...             ...    ...                                                ...  \n",
       "47054             0      1  Anyone going to Seattle International Film Fes...  \n",
       "47055             0      1  Is taking Physics and ochem at the same time a...  \n",
       "47056             0      1  Microbio and Weed-out classes I know this subr...  \n",
       "47057             0      1  Did I miss the window for a house rental for t...  \n",
       "47058             0      1   Varanasi Summer Internship Decision Does anyo...  \n",
       "\n",
       "[47059 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"/kaggle/input/notcombined/r_udub_posts_filtered.csv\")\n",
    "df = df_raw.copy()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6870d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:24:37.594263Z",
     "iopub.status.busy": "2024-05-03T23:24:37.593839Z",
     "iopub.status.idle": "2024-05-03T23:24:49.993351Z",
     "shell.execute_reply": "2024-05-03T23:24:49.992016Z"
    },
    "papermill": {
     "duration": 12.410066,
     "end_time": "2024-05-03T23:24:49.996787",
     "exception": false,
     "start_time": "2024-05-03T23:24:37.586721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe: (9031, 2)\n",
      "Pre-processed dataframe: (9012, 2)\n"
     ]
    }
   ],
   "source": [
    "text_columns = [\"combined_text\"]\n",
    "\n",
    "df_raw = pd.read_csv(\"/kaggle/input/alldatafiltered/AllDataFilteredNoBody.csv\")\n",
    "df = df_raw.copy()\n",
    "df[\"combined_text\"] = df[\"combined_text\"].fillna(\"\")\n",
    "\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "# Create text column based on title, description, and content\n",
    "df[\"text\"] = df[text_columns].apply(lambda x: \" | \".join(x), axis=1)\n",
    "df[\"tokens\"] = df[\"text\"].map(lambda x: clean_text(x, word_tokenize, stopwords.words(\"english\")))\n",
    "\n",
    "# Remove duplicated after preprocessing\n",
    "_, idx = np.unique(df[\"tokens\"], return_index=True)\n",
    "df = df.iloc[idx, :]\n",
    "\n",
    "# Remove empty values and keep relevant columns\n",
    "df = df.loc[df.tokens.map(lambda x: len(x) > 0), [\"text\", \"tokens\"]]\n",
    "\n",
    "docs = df[\"text\"].values\n",
    "tokenized_docs = df[\"tokens\"].values\n",
    "\n",
    "print(f\"Original dataframe: {df_raw.shape}\")\n",
    "print(f\"Pre-processed dataframe: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d73bbba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:24:50.009154Z",
     "iopub.status.busy": "2024-05-03T23:24:50.008787Z",
     "iopub.status.idle": "2024-05-03T23:24:54.068258Z",
     "shell.execute_reply": "2024-05-03T23:24:54.067116Z"
    },
    "papermill": {
     "duration": 4.069053,
     "end_time": "2024-05-03T23:24:54.071318",
     "exception": false,
     "start_time": "2024-05-03T23:24:50.002265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=tokenized_docs, vector_size=100, workers=1, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfc0bae2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:24:54.084702Z",
     "iopub.status.busy": "2024-05-03T23:24:54.083996Z",
     "iopub.status.idle": "2024-05-03T23:24:54.100962Z",
     "shell.execute_reply": "2024-05-03T23:24:54.099836Z"
    },
    "papermill": {
     "duration": 0.027797,
     "end_time": "2024-05-03T23:24:54.104727",
     "exception": false,
     "start_time": "2024-05-03T23:24:54.076930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('series', 0.9823327660560608),\n",
       " ('physics', 0.9782159924507141),\n",
       " ('cse', 0.9718117713928223),\n",
       " ('phys', 0.9675642848014832),\n",
       " ('intro', 0.9665501713752747),\n",
       " ('bio', 0.9648613929748535),\n",
       " ('gen', 0.9615781903266907),\n",
       " ('stat', 0.956072986125946),\n",
       " ('econ', 0.9558734893798828),\n",
       " ('calc', 0.9534657001495361)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"math\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "597c21d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:24:54.131073Z",
     "iopub.status.busy": "2024-05-03T23:24:54.130410Z",
     "iopub.status.idle": "2024-05-03T23:24:55.819916Z",
     "shell.execute_reply": "2024-05-03T23:24:55.818718Z"
    },
    "papermill": {
     "duration": 1.706111,
     "end_time": "2024-05-03T23:24:55.822725",
     "exception": false,
     "start_time": "2024-05-03T23:24:54.116614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9012, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorize(list_of_docs, model):\n",
    "    \"\"\"Generate vectors for list of documents using a Word Embedding\n",
    "\n",
    "    Args:\n",
    "        list_of_docs: List of documents\n",
    "        model: Gensim's Word Embedding\n",
    "\n",
    "    Returns:\n",
    "        List of document vectors\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    for tokens in list_of_docs:\n",
    "        zero_vector = np.zeros(model.vector_size)\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            if token in model.wv:\n",
    "                try:\n",
    "                    vectors.append(model.wv[token])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        if vectors:\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis=0)\n",
    "            features.append(avg_vec)\n",
    "        else:\n",
    "            features.append(zero_vector)\n",
    "    return features\n",
    "    \n",
    "vectorized_docs = vectorize(tokenized_docs, model=model)\n",
    "len(vectorized_docs), len(vectorized_docs[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7529fef6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:24:55.836067Z",
     "iopub.status.busy": "2024-05-03T23:24:55.835691Z",
     "iopub.status.idle": "2024-05-03T23:24:55.845847Z",
     "shell.execute_reply": "2024-05-03T23:24:55.844681Z"
    },
    "papermill": {
     "duration": 0.019743,
     "end_time": "2024-05-03T23:24:55.848271",
     "exception": false,
     "start_time": "2024-05-03T23:24:55.828528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mbkmeans_clusters(\n",
    "\tX, \n",
    "    k, \n",
    "    mb, \n",
    "    print_silhouette_values, \n",
    "):\n",
    "    \"\"\"Generate clusters and print Silhouette metrics using MBKmeans\n",
    "\n",
    "    Args:\n",
    "        X: Matrix of features.\n",
    "        k: Number of clusters.\n",
    "        mb: Size of mini-batches.\n",
    "        print_silhouette_values: Print silhouette values per cluster.\n",
    "\n",
    "    Returns:\n",
    "        Trained clustering model and labels based on X.\n",
    "    \"\"\"\n",
    "    km = MiniBatchKMeans(n_clusters=k, batch_size=mb).fit(X)\n",
    "    print(f\"For n_clusters = {k}\")\n",
    "    print(f\"Silhouette coefficient: {silhouette_score(X, km.labels_):0.2f}\")\n",
    "    print(f\"Inertia:{km.inertia_}\")\n",
    "\n",
    "    if print_silhouette_values:\n",
    "        sample_silhouette_values = silhouette_samples(X, km.labels_)\n",
    "        print(f\"Silhouette values:\")\n",
    "        silhouette_values = []\n",
    "        for i in range(k):\n",
    "            cluster_silhouette_values = sample_silhouette_values[km.labels_ == i]\n",
    "            silhouette_values.append(\n",
    "                (\n",
    "                    i,\n",
    "                    cluster_silhouette_values.shape[0],\n",
    "                    cluster_silhouette_values.mean(),\n",
    "                    cluster_silhouette_values.min(),\n",
    "                    cluster_silhouette_values.max(),\n",
    "                )\n",
    "            )\n",
    "        silhouette_values = sorted(\n",
    "            silhouette_values, key=lambda tup: tup[2], reverse=True\n",
    "        )\n",
    "        for s in silhouette_values:\n",
    "            print(\n",
    "                f\"    Cluster {s[0]}: Size:{s[1]} | Avg:{s[2]:.2f} | Min:{s[3]:.2f} | Max: {s[4]:.2f}\"\n",
    "            )\n",
    "    return km, km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da5904af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:24:55.864073Z",
     "iopub.status.busy": "2024-05-03T23:24:55.863689Z",
     "iopub.status.idle": "2024-05-03T23:24:58.831121Z",
     "shell.execute_reply": "2024-05-03T23:24:58.829984Z"
    },
    "papermill": {
     "duration": 2.979266,
     "end_time": "2024-05-03T23:24:58.833375",
     "exception": false,
     "start_time": "2024-05-03T23:24:55.854109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 11\n",
      "Silhouette coefficient: 0.11\n",
      "Inertia:7243.462248700706\n",
      "Silhouette values:\n",
      "    Cluster 7: Size:1327 | Avg:0.16 | Min:0.00 | Max: 0.34\n",
      "    Cluster 8: Size:1038 | Avg:0.15 | Min:-0.11 | Max: 0.40\n",
      "    Cluster 2: Size:867 | Avg:0.15 | Min:-0.09 | Max: 0.37\n",
      "    Cluster 9: Size:896 | Avg:0.13 | Min:-0.03 | Max: 0.33\n",
      "    Cluster 0: Size:929 | Avg:0.12 | Min:-0.10 | Max: 0.35\n",
      "    Cluster 5: Size:616 | Avg:0.11 | Min:-0.12 | Max: 0.35\n",
      "    Cluster 4: Size:1005 | Avg:0.10 | Min:-0.05 | Max: 0.28\n",
      "    Cluster 6: Size:899 | Avg:0.10 | Min:-0.14 | Max: 0.35\n",
      "    Cluster 1: Size:503 | Avg:0.04 | Min:-0.17 | Max: 0.26\n",
      "    Cluster 10: Size:510 | Avg:0.04 | Min:-0.14 | Max: 0.29\n",
      "    Cluster 3: Size:422 | Avg:0.02 | Min:-0.19 | Max: 0.25\n"
     ]
    }
   ],
   "source": [
    "clustering, cluster_labels = mbkmeans_clusters(\n",
    "\tX=vectorized_docs,\n",
    "    k=11,\n",
    "    mb=500,\n",
    "    print_silhouette_values=True,\n",
    ")\n",
    "df_clusters = pd.DataFrame({\n",
    "    \"text\": docs,\n",
    "    \"tokens\": [\" \".join(text) for text in tokenized_docs],\n",
    "    \"cluster\": cluster_labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57c862fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:24:58.847446Z",
     "iopub.status.busy": "2024-05-03T23:24:58.847065Z",
     "iopub.status.idle": "2024-05-03T23:24:58.867256Z",
     "shell.execute_reply": "2024-05-03T23:24:58.865701Z"
    },
    "papermill": {
     "duration": 0.031954,
     "end_time": "2024-05-03T23:24:58.871449",
     "exception": false,
     "start_time": "2024-05-03T23:24:58.839495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most representative terms per cluster (based on centroids):\n",
      "Cluster 0: wanting pmp internships accepting transfers \n",
      "Cluster 1: normal four til deans lockdown \n",
      "Cluster 2: teaching phys121 python heavy prepare \n",
      "Cluster 3: vlpa retaking ed engr fulfill \n",
      "Cluster 4: potentially frustrated anxiety hella wish \n",
      "Cluster 5: premed pursuing neuro ce psychology \n",
      "Cluster 6: udistrict commuting closer furnished cheapest \n",
      "Cluster 7: guess happy anxious knowing motivated \n",
      "Cluster 8: bioe polisci affect initially hopefully \n",
      "Cluster 9: retake core doable mgmt qsci \n",
      "Cluster 10: particular everybody suggestion leader opinions \n"
     ]
    }
   ],
   "source": [
    "print(\"Most representative terms per cluster (based on centroids):\")\n",
    "for i in range(11):\n",
    "    tokens_per_cluster = \"\"\n",
    "    most_representative = model.wv.most_similar(positive=[clustering.cluster_centers_[i]], topn=5)\n",
    "    for t in most_representative:\n",
    "        tokens_per_cluster += f\"{t[0]} \"\n",
    "    print(f\"Cluster {i}: {tokens_per_cluster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "719b9f8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:24:58.900297Z",
     "iopub.status.busy": "2024-05-03T23:24:58.899588Z",
     "iopub.status.idle": "2024-05-03T23:24:58.938213Z",
     "shell.execute_reply": "2024-05-03T23:24:58.936783Z"
    },
    "papermill": {
     "duration": 0.057974,
     "end_time": "2024-05-03T23:24:58.942563",
     "exception": false,
     "start_time": "2024-05-03T23:24:58.884589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human centered design and engineering and pre-pa track? i’m an incoming freshman ( i also have college credits from running start) and i’m still figuring stuff out. currently, hcde has caught my eye and i’m still interested in medicine. how hard is it to get into hcde? any advice? do people do engineering discipline and pre-health track?\n",
      "-------------\n",
      "informatics major admission? hi :) so i’m looking to apply for informatics in the upcoming cycle and i’m nervous because it’s getting competitive and this was my first quarter at uw so my gpa is down a bit in addition to mental health reasons. i also came in with about 99 credits from running start so i got most of the prerequisites covered besides cs and stats. what advice would you have to make my application standout for the admissions committee? any clubs? programs? general advice? if you applied and got in, what did you do for your application?\n",
      "-------------\n",
      "electrical engineering workload? i’m a high school senior applying to uw. i’m still debating whether to apply da to cse or dtc to engrud. i would preferably want to do cs but since the direct acceptance rate for engineering undeclared is a fair bit higher, i’ve been considering applying through that to then hopefully be placed in electrical engineering which seems to be the engineering major closest to cse and one that i would enjoy being in. \n",
      "\n",
      "i’m definitely aware that engineering in general has much more intensive coursework than computer science and there’s the stereotype of engineering majors not having any time to relax. i still wanted to ask any current ee majors about how manageable having a social life, doing well in classes, and having extracurriculars is at the uw program specifically?\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "test_cluster = 5\n",
    "most_representative_docs = np.argsort(\n",
    "    np.linalg.norm(vectorized_docs - clustering.cluster_centers_[test_cluster], axis=1)\n",
    ")\n",
    "for d in most_representative_docs[:3]:\n",
    "    print(docs[d])\n",
    "    print(\"-------------\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4934062,
     "sourceId": 8305959,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4934081,
     "sourceId": 8306011,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 40.855553,
   "end_time": "2024-05-03T23:24:59.980819",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-03T23:24:19.125266",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
